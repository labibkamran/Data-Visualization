{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a650be",
   "metadata": {},
   "source": [
    "# Load & Quick Scan\n",
    "\n",
    "I start every cleaning job by loading the file and checking that the columns look familiar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3747ea5",
   "metadata": {},
   "source": [
    "### Task 1 \u2013 Load the dataset\n",
    "\n",
    "I read the CSV into a DataFrame, keeping an eye on encoding errors so nothing breaks later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b791af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "data_path = Path('consumer_complaints_unclean.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "df_raw = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768d417",
   "metadata": {},
   "source": [
    "### Task 2 \u2013 Shape and data types\n",
    "\n",
    "Right after loading I print the shape and `dtypes`. This tells me how big the file is and which columns need type fixes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b99ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 16)\n",
      "Complaint ID                      int64\n",
      "Date Received                    object\n",
      "Date Sent to Company             object\n",
      "Product                          object\n",
      "Sub-product                      object\n",
      "Issue                            object\n",
      "Company                          object\n",
      "State                            object\n",
      "ZIP code                         object\n",
      "City                             object\n",
      "Company response to consumer     object\n",
      "Timely response?                 object\n",
      "Consumer disputed?               object\n",
      "Latitude                        float64\n",
      "Longitude                       float64\n",
      "Status                           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71eddd7",
   "metadata": {},
   "source": [
    "### Task 3 \u2013 Peek at the first rows\n",
    "\n",
    "A quick `.head()` lets me spot weird spellings or date formats before I automate anything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58226af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complaint ID</th>\n",
       "      <th>Date Received</th>\n",
       "      <th>Date Sent to Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>City</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>mortgage</td>\n",
       "      <td>Interest rate</td>\n",
       "      <td></td>\n",
       "      <td>Metro Loans</td>\n",
       "      <td>NY</td>\n",
       "      <td>75285</td>\n",
       "      <td>new york</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.312932</td>\n",
       "      <td>-91.462816</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Collections</td>\n",
       "      <td>Collection harassment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>43383</td>\n",
       "      <td>miami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>42.236514</td>\n",
       "      <td>-103.703588</td>\n",
       "      <td>Resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>2023-10-20</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td></td>\n",
       "      <td>Interest rate</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>43864</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.279018</td>\n",
       "      <td>-94.258898</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>Student  loan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fees</td>\n",
       "      <td>Metro Loans</td>\n",
       "      <td>GA</td>\n",
       "      <td>123</td>\n",
       "      <td>new york</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>34.924120</td>\n",
       "      <td>-85.770266</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Adjustable loan</td>\n",
       "      <td>Collection harassment</td>\n",
       "      <td>United Credit</td>\n",
       "      <td>PA</td>\n",
       "      <td>62086</td>\n",
       "      <td>New York</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.643178</td>\n",
       "      <td>-86.962992</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Complaint ID Date Received Date Sent to Company        Product  \\\n",
       "0        100000    2023-11-10           2024-01-01       mortgage   \n",
       "1        100001    2023-03-12           2023-03-21       MORTGAGE   \n",
       "2        100002    2023-10-20           2023-11-27                  \n",
       "3        100003    2023-02-17           2023-03-13  Student  loan   \n",
       "4        100004    2023-11-21           2023-11-23    credit card   \n",
       "\n",
       "       Sub-product                  Issue        Company State ZIP code  \\\n",
       "0    Interest rate                           Metro Loans    NY    75285   \n",
       "1      Collections  Collection harassment            NaN    FL    43383   \n",
       "2    Interest rate                  Other            NaN    NY    43864   \n",
       "3              NaN                   Fees    Metro Loans    GA      123   \n",
       "4  Adjustable loan  Collection harassment  United Credit    PA    62086   \n",
       "\n",
       "         City Company response to consumer Timely response?  \\\n",
       "0   new york                           NaN                N   \n",
       "1       miami                          NaN              NaN   \n",
       "2     Unknown                      Unknown            FALSE   \n",
       "3   new york                           NaN          Unknown   \n",
       "4    New York                      Unknown              Yes   \n",
       "\n",
       "  Consumer disputed?   Latitude   Longitude    Status  \n",
       "0                NaN  42.312932  -91.462816    Closed  \n",
       "1                  N  42.236514 -103.703588  Resolved  \n",
       "2                NaN  41.279018  -94.258898    Closed  \n",
       "3                 No  34.924120  -85.770266            \n",
       "4                NaN  35.643178  -86.962992   Unknown  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36a274",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "\n",
    "Consumer complaints are usually messy, so I check the missingness early.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b0eb9",
   "metadata": {},
   "source": [
    "### Task 4 \u2013 Missing-value percentages\n",
    "\n",
    "I compute the percent of nulls in every column so I can talk about the scale of the problem with confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa7891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company response to consumer    33.529412\n",
       "Sub-product                     26.568627\n",
       "Consumer disputed?              24.019608\n",
       "Company                         17.598039\n",
       "City                            14.313725\n",
       "State                           13.970588\n",
       "Timely response?                12.156863\n",
       "Product                          3.872549\n",
       "Issue                            3.431373\n",
       "Date Received                    0.000000\n",
       "Date Sent to Company             0.000000\n",
       "Complaint ID                     0.000000\n",
       "ZIP code                         0.000000\n",
       "Latitude                         0.000000\n",
       "Longitude                        0.000000\n",
       "Status                           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_pct = df.isna().mean().mul(100).sort_values(ascending=False)\n",
    "missing_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e791cd",
   "metadata": {},
   "source": [
    "### Task 5 \u2013 Columns above 80% missing\n",
    "\n",
    "Here I list the worst offenders. If a column is mostly blank, I probably will not rely on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315e3993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_missing = missing_pct[missing_pct > 80]\n",
    "high_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8a994",
   "metadata": {},
   "source": [
    "### Task 6 \u2013 Plan for high-missing columns\n",
    "\n",
    "Based on those numbers I write down whether I will drop, impute, or just document the sparse columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc2cd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2040, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = high_missing.index.tolist()\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a73a22",
   "metadata": {},
   "source": [
    "# Duplicates\n",
    "\n",
    "Duplicate complaints can create fake trends, so I handle them next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d75203",
   "metadata": {},
   "source": [
    "### Task 7 \u2013 Count duplicates\n",
    "\n",
    "I count how many rows repeat the same complaint ID. Even a few duplicates matter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a0f55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = df.duplicated().sum()\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b492313",
   "metadata": {},
   "source": [
    "### Task 8 \u2013 Drop duplicates, keep the latest entry\n",
    "\n",
    "Using the complaint ID and `date_received`, I keep the newest record per ID and drop the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329f6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_before_dedup = df.shape\n",
    "df = df.sort_values(by='Date Received', key=lambda s: pd.to_datetime(s, errors='coerce'))\n",
    "df = df.drop_duplicates(subset='Complaint ID', keep='last')\n",
    "shape_after_dedup = df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7bdbd",
   "metadata": {},
   "source": [
    "### Task 9 \u2013 Shapes before vs after\n",
    "\n",
    "I print the DataFrame shape before and after deduping so the change is clear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b99f9974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 16)\n",
      "(1885, 16)\n"
     ]
    }
   ],
   "source": [
    "print(shape_before_dedup)\n",
    "print(shape_after_dedup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969031b",
   "metadata": {},
   "source": [
    "# Data Types & Parsing\n",
    "\n",
    "Now I fix the types that affect later calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af198c9",
   "metadata": {},
   "source": [
    "### Task 10 \u2013 Convert date fields\n",
    "\n",
    "I parse the date columns with `pd.to_datetime` so I can measure response times later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40269407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date Received           datetime64[ns]\n",
       "Date Sent to Company    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date Received'] = pd.to_datetime(df['Date Received'], errors='coerce')\n",
    "df['Date Sent to Company'] = pd.to_datetime(df['Date Sent to Company'], errors='coerce')\n",
    "df[['Date Received', 'Date Sent to Company']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faded155",
   "metadata": {},
   "source": [
    "### Task 11 \u2013 Clean geographic/postal numbers\n",
    "\n",
    "ZIP codes and coordinates should be numeric, so I coerce them with errors set to `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db734af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP code     float64\n",
       "Latitude     float64\n",
       "Longitude    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ZIP code'] = pd.to_numeric(df['ZIP code'], errors='coerce')\n",
    "df['Latitude'] = pd.to_numeric(df['Latitude'], errors='coerce')\n",
    "df['Longitude'] = pd.to_numeric(df['Longitude'], errors='coerce')\n",
    "df[['ZIP code', 'Latitude', 'Longitude']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b0629",
   "metadata": {},
   "source": [
    "### Task 12 \u2013 Keep location labels as strings\n",
    "\n",
    "Fields like city and state need to stay as text. I enforce string dtype to avoid surprises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b281bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product    string[python]\n",
       "State      string[python]\n",
       "City       string[python]\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Product'] = df['Product'].astype('string')\n",
    "df['State'] = df['State'].astype('string')\n",
    "df['City'] = df['City'].astype('string')\n",
    "df[['Product', 'State', 'City']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd3e3e",
   "metadata": {},
   "source": [
    "# Renaming & Category Standardization\n",
    "\n",
    "Consistent naming makes the dataset easier to reuse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb15cc",
   "metadata": {},
   "source": [
    "### Task 13 \u2013 Rename columns to snake_case\n",
    "\n",
    "I rename everything to lowercase snake_case, which works nicely in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0bed7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complaint_id',\n",
       " 'date_received',\n",
       " 'date_sent_to_company',\n",
       " 'product',\n",
       " 'sub_product',\n",
       " 'issue',\n",
       " 'company',\n",
       " 'state',\n",
       " 'zip_code',\n",
       " 'city',\n",
       " 'company_response_to_consumer',\n",
       " 'timely_response',\n",
       " 'consumer_disputed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'status']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns=lambda c: re.sub(r'[^0-9a-zA-Z]+', '_', c.strip().lower()).strip('_'))\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3235226",
   "metadata": {},
   "source": [
    "### Task 14 \u2013 Trim spaces and tidy casing\n",
    "\n",
    "Manual data entry often leaves extra spaces. I strip whitespace and apply title case to the public-facing labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54d03d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>Il</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>Student Loan</td>\n",
       "      <td>Ny</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>Bank Account</td>\n",
       "      <td>Il</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Nc</td>\n",
       "      <td>Charlotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Mi</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               product state       city\n",
       "1709  Credit Reporting    Il    Chicago\n",
       "1248      Student Loan    Ny    Unknown\n",
       "1169      Bank Account    Il   New York\n",
       "1242       Credit Card    Nc  Charlotte\n",
       "1499          Mortgage    Mi   New York"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['product'] = df['product'].str.strip().str.title()\n",
    "df['state'] = df['state'].str.strip().str.title()\n",
    "df['city'] = df['city'].str.strip().str.title()\n",
    "df[['product', 'state', 'city']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d2bab",
   "metadata": {},
   "source": [
    "### Task 15 \u2013 Fix inconsistent product names\n",
    "\n",
    "If the same product appears with multiple spellings, I replace them with one clean label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b8e18ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit Reporting', 'Student Loan', 'Bank Account', 'Credit Card',\n",
       "       'Mortgage', 'Credit  Card', 'Unknown', 'Debt Collection',\n",
       "       'Student  Loan', 'Debt  Collection', <NA>, ''], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "product_original = df['product'].copy()\nproduct_map = {\n    'credit card': 'Credit Card',\n    'credit card or prepaid card': 'Credit Card Or Prepaid Card',\n    'bank account or service': 'Bank Account Or Service',\n    'consumer loan': 'Consumer Loan',\n    'debt collection': 'Debt Collection',\n    'student loan': 'Student Loan',\n    'mortgage': 'Mortgage',\n    'vehicle loan or lease': 'Vehicle Loan Or Lease',\n    'payday loan': 'Payday Loan',\n    'credit reporting': 'Credit Reporting',\n    'money transfers': 'Money Transfers'\n}\ndf['product'] = df['product'].str.lower().map(product_map).fillna(product_original)\ndf['product'].unique()"
  },
  {
   "cell_type": "markdown",
   "id": "d9b3a3ca",
   "metadata": {},
   "source": [
    "# Null-like Tokens, Outliers & Sanity Checks\n",
    "\n",
    "Before exporting, I get rid of fake null values and obvious outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ae480",
   "metadata": {},
   "source": [
    "### Task 16 \u2013 Replace null-like tokens\n",
    "\n",
    "Values such as `'N/A'` or `'Not Provided'` become real `NaN` so downstream stats behave.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7ac040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complaint_id                      0\n",
       "date_received                     0\n",
       "date_sent_to_company              0\n",
       "product                         144\n",
       "sub_product                     494\n",
       "issue                            95\n",
       "company                         605\n",
       "state                           535\n",
       "zip_code                        159\n",
       "city                            462\n",
       "company_response_to_consumer    927\n",
       "timely_response                 473\n",
       "consumer_disputed               455\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "status                          313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_tokens = ['N/A', 'n/a', 'Unknown', 'unknown', 'UNKNOWN', '']\n",
    "df = df.replace(null_tokens, pd.NA)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c803ca2",
   "metadata": {},
   "source": [
    "### Task 17 \u2013 Latitude/longitude outliers\n",
    "\n",
    "I run a simple IQR check on the coordinates to flag impossible points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06432f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>-98.387197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>-83.962667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-82.441493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>32.525855</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-114.081161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>34.150904</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>-91.745148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>59.575738</td>\n",
       "      <td>-88.135644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>48.794043</td>\n",
       "      <td>-400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>18.303842</td>\n",
       "      <td>-100.709548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows \u00d7 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude   longitude\n",
       "423   200.000000  -98.387197\n",
       "1027  999.000000  -83.962667\n",
       "618  -200.000000  -82.441493\n",
       "975    32.525855  400.000000\n",
       "1196 -200.000000 -114.081161\n",
       "...          ...         ...\n",
       "208    34.150904  400.000000\n",
       "1570  999.000000  -91.745148\n",
       "1460   59.575738  -88.135644\n",
       "369    48.794043 -400.000000\n",
       "107    18.303842 -100.709548\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_q1 = df['latitude'].quantile(0.25)\n",
    "lat_q3 = df['latitude'].quantile(0.75)\n",
    "lat_iqr = lat_q3 - lat_q1\n",
    "lon_q1 = df['longitude'].quantile(0.25)\n",
    "lon_q3 = df['longitude'].quantile(0.75)\n",
    "lon_iqr = lon_q3 - lon_q1\n",
    "lat_bounds = (lat_q1 - 1.5 * lat_iqr, lat_q3 + 1.5 * lat_iqr)\n",
    "lon_bounds = (lon_q1 - 1.5 * lon_iqr, lon_q3 + 1.5 * lon_iqr)\n",
    "lat_long_outliers = df[(df['latitude'] < lat_bounds[0]) | (df['latitude'] > lat_bounds[1]) | (df['longitude'] < lon_bounds[0]) | (df['longitude'] > lon_bounds[1])]\n",
    "lat_long_outliers[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360016c0",
   "metadata": {},
   "source": [
    "### Task 18 \u2013 Validate five-digit ZIP codes\n",
    "\n",
    "I make sure ZIP codes stay within the normal five-digit range; bad ones become missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198f0e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709    00123\n",
       "1248    75201\n",
       "1169    40722\n",
       "1242    00000\n",
       "1499    54760\n",
       "Name: zip_code, dtype: string"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "zip_int = pd.to_numeric(df['zip_code'], errors='coerce').astype('Int64')\nzip_str = zip_int.astype('string').str.zfill(5)\nzip_mask = zip_str.str.len().eq(5) & zip_str.str.isnumeric()\ndf['zip_code'] = zip_str.where(zip_mask, pd.NA)\ndf['zip_code'].head()"
  },
  {
   "cell_type": "markdown",
   "id": "28707a03",
   "metadata": {},
   "source": [
    "# Derived Feature & Export\n",
    "\n",
    "With the basics fixed, I add one helpful metric and ship a clean subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48b47b",
   "metadata": {},
   "source": [
    "### Task 19 \u2013 Response time in days\n",
    "\n",
    "Subtracting the received and sent dates gives me the number of days it took to respond to each complaint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7c68ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709    58\n",
       "1248    57\n",
       "1169    37\n",
       "1242    10\n",
       "1499    38\n",
       "Name: response_time_days, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['response_time_days'] = (df['date_sent_to_company'] - df['date_received']).dt.days\n",
    "df['response_time_days'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7bf90",
   "metadata": {},
   "source": [
    "### Task 20 \u2013 Choose the final columns\n",
    "\n",
    "I keep only the columns that survived cleaning and are useful for dashboards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c4c4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>issue</th>\n",
       "      <th>company</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>status</th>\n",
       "      <th>company_response_to_consumer</th>\n",
       "      <th>timely_response</th>\n",
       "      <th>consumer_disputed</th>\n",
       "      <th>response_time_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>101709</td>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>Collections</td>\n",
       "      <td>Other</td>\n",
       "      <td>Northstar Finance</td>\n",
       "      <td>Il</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>00123</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Y</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>101248</td>\n",
       "      <td>Student Loan</td>\n",
       "      <td>Fixed loan</td>\n",
       "      <td>Identity theft</td>\n",
       "      <td>FinServ Co</td>\n",
       "      <td>Ny</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>75201</td>\n",
       "      <td>Open</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>101169</td>\n",
       "      <td>Bank Account</td>\n",
       "      <td>Fixed loan</td>\n",
       "      <td>Identity theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Il</td>\n",
       "      <td>New York</td>\n",
       "      <td>40722</td>\n",
       "      <td></td>\n",
       "      <td>In progress</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>101242</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Interest rate</td>\n",
       "      <td>Identity theft</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Nc</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>00000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>101499</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Collections</td>\n",
       "      <td>Other</td>\n",
       "      <td>Northstar Finance</td>\n",
       "      <td>Mi</td>\n",
       "      <td>New York</td>\n",
       "      <td>54760</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      complaint_id           product    sub_product           issue  \\\n",
       "1709        101709  Credit Reporting    Collections           Other   \n",
       "1248        101248      Student Loan     Fixed loan  Identity theft   \n",
       "1169        101169      Bank Account     Fixed loan  Identity theft   \n",
       "1242        101242       Credit Card  Interest rate  Identity theft   \n",
       "1499        101499          Mortgage    Collections           Other   \n",
       "\n",
       "                company state       city zip_code       status  \\\n",
       "1709  Northstar Finance    Il    Chicago    00123  In Progress   \n",
       "1248         FinServ Co    Ny       <NA>    75201         Open   \n",
       "1169                NaN    Il   New York    40722                \n",
       "1242               <NA>    Nc  Charlotte    00000         <NA>   \n",
       "1499  Northstar Finance    Mi   New York    54760         <NA>   \n",
       "\n",
       "     company_response_to_consumer timely_response consumer_disputed  \\\n",
       "1709                          NaN            <NA>                 Y   \n",
       "1248                         <NA>             Yes               Yes   \n",
       "1169                  In progress            <NA>               NaN   \n",
       "1242                       Closed             NaN                No   \n",
       "1499                         <NA>               N                 Y   \n",
       "\n",
       "      response_time_days  \n",
       "1709                  58  \n",
       "1248                  57  \n",
       "1169                  37  \n",
       "1242                  10  \n",
       "1499                  38  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = ['complaint_id', 'product', 'sub_product', 'issue', 'company', 'state', 'city', 'zip_code', 'status', 'company_response_to_consumer', 'timely_response', 'consumer_disputed', 'response_time_days']\n",
    "df_subset = df[selected_columns].copy()\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50a804",
   "metadata": {},
   "source": [
    "### Task 21 \u2013 Export the cleaned data\n",
    "\n",
    "Finally I save the tidy DataFrame so I can plug it into Tableau or Power BI without repeating the prep work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7bae578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = Path('consumer_complaints_cleaned.csv')\n",
    "df_subset.to_csv(output_path, index=False)\n",
    "output_path.exists()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}